<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>BERT情感分析 | Re_mioの小破站</title><meta name="author" content="Lishengshang"><meta name="copyright" content="Lishengshang"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="该文章由AI生成   BERT情感分析训练教程 -..."><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "BERT情感分析",
  "url": "https://lishengshang.github.io/posts/c09a4ded/",
  "image": "https://i.111666.best/image/0wIZQ3j5GIDM5obXp0yA3f.png",
  "datePublished": "2025-06-08T05:24:36.000Z",
  "dateModified": "2025-06-08T06:23:58.367Z",
  "author": [
    {
      "@type": "Person",
      "name": "Lishengshang",
      "url": "https://lishengshang.github.io/"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.ico"><link rel="canonical" href="https://lishengshang.github.io/posts/c09a4ded/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin=""/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!true && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":true},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: {"chs_to_cht":"已切换为繁体中文","cht_to_chs":"已切换为简体中文","day_to_night":"已切换为深色模式","night_to_day":"已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"bottom-center"},
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'BERT情感分析',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><link rel="stylesheet" href="/css/custom.css"><link rel="stylesheet" href="/css/loading.css"><link rel="stylesheet" href="/css/loading.css"> <canvas id="bubble_canvas" style="position:fixed;top:0;left:0;width:100%;height:100%;z-index:999999;pointer-events:none"></canvas><!-- hexo injector head_end start --><link rel="stylesheet" href="https://unpkg.zhimg.com/hexo-butterfly-footer-beautify@1.0.0/lib/runtime.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://unpkg.zhimg.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload="this.media='all'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head><body><div id="loading-box" onclick="document.getElementById(&quot;loading-box&quot;).classList.add(&quot;loaded&quot;)"><div class="loading-bg"><img class="loading-img nolazyload"/><div class="loading-image-dot"></div><div id="loading-percentage">0%</div></div></div><script>const loadingPercentage = document.getElementById("loading-percentage");
loadingPercentage.style.color = "black";
let loadingPercentageTimer = setInterval(function() {
  var progressBar = document.querySelector(".pace-progress");
  if (!progressBar) return
  var currentValue = progressBar.getAttribute("data-progress-text");
  if (currentValue !== loadingPercentage.textContent) {
    loadingPercentage.textContent = currentValue;
    if (currentValue === "100%") {
      clearInterval(loadingPercentageTimer);
    }
  }
}, 100);
const preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")
  }
}
window.addEventListener('load',()=> { preloader.endLoading() })

if (true) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><div id="web_bg" style="background-image: url(/img/jiatenghui.jpeg);"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="https://avatars.githubusercontent.com/u/149315495?s=400&amp;u=35789284796e584dbaaac1634d60d423dde4b39e&amp;v=4" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">2</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">2</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> 链接</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://i.111666.best/image/0wIZQ3j5GIDM5obXp0yA3f.png);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><img class="site-icon" src="/img/favicon_weimei.ico" alt="Logo"><span class="site-name">Re_mioの小破站</span></a><a class="nav-page-title" href="/"><span class="site-name">BERT情感分析</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> 链接</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">BERT情感分析</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-06-08T05:24:36.000Z" title="发表于 2025-06-08 13:24:36">2025-06-08</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-06-08T06:23:58.367Z" title="更新于 2025-06-08 14:23:58">2025-06-08</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/AI/">AI</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">3.4k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>16分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><section class="main-hero-waves-area waves-area"><svg class="waves-svg" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M -160 44 c 30 0 58 -18 88 -18 s 58 18 88 18 s 58 -18 88 -18 s 58 18 88 18 v 44 h -352 Z"></path></defs><g class="parallax"><use href="#gentle-wave" x="48" y="0"></use><use href="#gentle-wave" x="48" y="3"></use><use href="#gentle-wave" x="48" y="5"></use><use href="#gentle-wave" x="48" y="7"></use></g></svg></section></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><div id="post-outdate-notice" data="{&quot;limitDay&quot;:365,&quot;messagePrev&quot;:&quot;文章具有时效性,可能已经过时了&quot;,&quot;messageNext&quot;:&quot;自上次更新,文章内容可能已过时。&quot;,&quot;postUpdate&quot;:&quot;2025-06-08 14:23:58&quot;}" hidden></div><div class="note blue icon-padding simple"><i class="note-icon fas fa-bullhorn"></i><p>该文章由AI生成</p>
</div>

<h1 id="BERT情感分析训练教程-IMDb数据集"><a href="#BERT情感分析训练教程-IMDb数据集" class="headerlink" title="BERT情感分析训练教程 - IMDb数据集"></a>BERT情感分析训练教程 - IMDb数据集</h1><p><strong>本教程使用BERT模型对IMDb电影评论数据集进行情感分析训练，从数据准备到模型部署的完整流程。</strong></p>
<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ol>
<li><a href="#1-%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87%E5%92%8C%E4%BE%9D%E8%B5%96%E5%AE%89%E8%A3%85">环境准备和依赖安装</a></li>
<li><a href="#2-%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8B%E8%BD%BD%E5%92%8C%E9%A2%84%E5%A4%84%E7%90%86">数据集下载和预处理</a></li>
<li><a href="#3-%E6%95%B0%E6%8D%AE%E9%9B%86%E7%B1%BB%E5%AE%9A%E4%B9%89">数据集类定义</a></li>
<li><a href="#4-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E5%B7%A5%E5%85%B7">模型训练工具</a></li>
<li><a href="#5-%E6%A8%A1%E5%9E%8B%E5%88%9D%E5%A7%8B%E5%8C%96">模型初始化</a></li>
<li><a href="#6-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83">模型训练</a></li>
<li><a href="#7-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0">模型评估</a></li>
<li><a href="#8-%E9%A2%84%E6%B5%8B%E7%A4%BA%E4%BE%8B">预测示例</a></li>
<li><a href="#9-%E6%A8%A1%E5%9E%8B%E4%BF%9D%E5%AD%98%E5%92%8C%E5%8A%A0%E8%BD%BD">模型保存和加载</a></li>
<li><a href="#10-%E6%80%BB%E7%BB%93%E5%92%8C%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E">总结和使用说明</a></li>
</ol>
<h2 id="1-环境准备和依赖安装"><a href="#1-环境准备和依赖安装" class="headerlink" title="1. 环境准备和依赖安装"></a>1. 环境准备和依赖安装</h2><p><strong>首先安装必要的Python包：</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install torch transformers scikit-learn tqdm requests numpy matplotlib seaborn</span><br></pre></td></tr></table></figure>

<p><strong>然后导入所需的库：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> tarfile</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> (</span><br><span class="line">    BertTokenizer, </span><br><span class="line">    BertForSequenceClassification, </span><br><span class="line">    AdamW, </span><br><span class="line">    get_linear_schedule_with_warmup</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置设备</span></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;使用设备: <span class="subst">&#123;device&#125;</span>&quot;</span>)</span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;GPU型号: <span class="subst">&#123;torch.cuda.get_device_name(<span class="number">0</span>)&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;GPU内存: <span class="subst">&#123;torch.cuda.get_device_properties(<span class="number">0</span>).total_memory / <span class="number">1024</span>**<span class="number">3</span>:<span class="number">.1</span>f&#125;</span> GB&quot;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="2-数据集下载和预处理"><a href="#2-数据集下载和预处理" class="headerlink" title="2. 数据集下载和预处理"></a>2. 数据集下载和预处理</h2><h3 id="下载IMDb数据集"><a href="#下载IMDb数据集" class="headerlink" title="下载IMDb数据集"></a>下载IMDb数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">download_imdb_dataset</span>(<span class="params">filename, url=<span class="string">&quot;http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz&quot;</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;下载IMDb数据集&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> os.path.exists(filename):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;filename&#125;</span> 已存在，跳过下载&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;正在下载 <span class="subst">&#123;filename&#125;</span>...&quot;</span>)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        response = requests.get(url, stream=<span class="literal">True</span>)</span><br><span class="line">        response.raise_for_status()</span><br><span class="line">        </span><br><span class="line">        total_size = <span class="built_in">int</span>(response.headers.get(<span class="string">&#x27;content-length&#x27;</span>, <span class="number">0</span>))</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(filename, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f, tqdm(</span><br><span class="line">            desc=filename,</span><br><span class="line">            total=total_size,</span><br><span class="line">            unit=<span class="string">&#x27;B&#x27;</span>,</span><br><span class="line">            unit_scale=<span class="literal">True</span>,</span><br><span class="line">            unit_divisor=<span class="number">1024</span>,</span><br><span class="line">        ) <span class="keyword">as</span> pbar:</span><br><span class="line">            <span class="keyword">for</span> chunk <span class="keyword">in</span> response.iter_content(chunk_size=<span class="number">8192</span>):</span><br><span class="line">                <span class="keyword">if</span> chunk:</span><br><span class="line">                    f.write(chunk)</span><br><span class="line">                    pbar.update(<span class="built_in">len</span>(chunk))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;filename&#125;</span> 下载完成&quot;</span>)</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;下载失败: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">raise</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">extract_imdb_dataset</span>(<span class="params">filename, extract_path=<span class="string">&#x27;./&#x27;</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;解压IMDb数据集&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> os.path.exists(os.path.join(extract_path, <span class="string">&#x27;aclImdb&#x27;</span>)):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;数据集已解压，跳过解压&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;正在解压 <span class="subst">&#123;filename&#125;</span>...&quot;</span>)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">with</span> tarfile.<span class="built_in">open</span>(filename, <span class="string">&#x27;r:gz&#x27;</span>) <span class="keyword">as</span> tar:</span><br><span class="line">            tar.extractall(path=extract_path)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;解压完成&quot;</span>)</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;解压失败: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">raise</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行下载和解压</span></span><br><span class="line">dataset_file = <span class="string">&#x27;aclImdb_v1.tar.gz&#x27;</span></span><br><span class="line">dataset_extract_path = <span class="string">&#x27;./&#x27;</span></span><br><span class="line"></span><br><span class="line">download_imdb_dataset(dataset_file)</span><br><span class="line">extract_imdb_dataset(dataset_file, dataset_extract_path)</span><br></pre></td></tr></table></figure>

<h3 id="加载和预处理数据"><a href="#加载和预处理数据" class="headerlink" title="加载和预处理数据"></a>加载和预处理数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">load_imdb_data</span>(<span class="params">extract_path</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;加载IMDb数据集&quot;&quot;&quot;</span></span><br><span class="line">    texts = []</span><br><span class="line">    labels = []</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 加载训练数据</span></span><br><span class="line">    <span class="keyword">for</span> label <span class="keyword">in</span> [<span class="string">&#x27;pos&#x27;</span>, <span class="string">&#x27;neg&#x27;</span>]:</span><br><span class="line">        path = os.path.join(extract_path, <span class="string">&#x27;aclImdb&#x27;</span>, <span class="string">&#x27;train&#x27;</span>, label)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(path):</span><br><span class="line">            <span class="keyword">raise</span> FileNotFoundError(<span class="string">f&quot;路径不存在: <span class="subst">&#123;path&#125;</span>&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        files = glob.glob(os.path.join(path, <span class="string">&#x27;*.txt&#x27;</span>))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;正在加载 <span class="subst">&#123;label&#125;</span> 数据: <span class="subst">&#123;<span class="built_in">len</span>(files)&#125;</span> 个文件&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> file <span class="keyword">in</span> tqdm(files, desc=<span class="string">f&quot;Loading <span class="subst">&#123;label&#125;</span>&quot;</span>):</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                <span class="keyword">with</span> <span class="built_in">open</span>(file, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                    text = f.read().strip()</span><br><span class="line">                    <span class="keyword">if</span> text:  <span class="comment"># 确保文本不为空</span></span><br><span class="line">                        texts.append(text)</span><br><span class="line">                        labels.append(<span class="number">1</span> <span class="keyword">if</span> label == <span class="string">&#x27;pos&#x27;</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;读取文件失败 <span class="subst">&#123;file&#125;</span>: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;总共加载 <span class="subst">&#123;<span class="built_in">len</span>(texts)&#125;</span> 条数据&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> texts, labels</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据</span></span><br><span class="line">texts, labels = load_imdb_data(dataset_extract_path)</span><br><span class="line">labels = np.array(labels)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据集统计</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\n数据集统计:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;总样本数: <span class="subst">&#123;<span class="built_in">len</span>(texts)&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;积极样本: <span class="subst">&#123;<span class="built_in">sum</span>(labels)&#125;</span> (<span class="subst">&#123;<span class="built_in">sum</span>(labels)/<span class="built_in">len</span>(labels)*<span class="number">100</span>:<span class="number">.1</span>f&#125;</span>%)&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;消极样本: <span class="subst">&#123;<span class="built_in">len</span>(labels) - <span class="built_in">sum</span>(labels)&#125;</span> (<span class="subst">&#123;(<span class="built_in">len</span>(labels) - <span class="built_in">sum</span>(labels))/<span class="built_in">len</span>(labels)*<span class="number">100</span>:<span class="number">.1</span>f&#125;</span>%)&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据集划分</span></span><br><span class="line">train_texts, test_texts, train_labels, test_labels = train_test_split(</span><br><span class="line">    texts, labels, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>, stratify=labels</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">train_texts, val_texts, train_labels, val_labels = train_test_split(</span><br><span class="line">    train_texts, train_labels, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>, stratify=train_labels</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;数据集划分:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;训练集大小: <span class="subst">&#123;<span class="built_in">len</span>(train_texts)&#125;</span> (<span class="subst">&#123;<span class="built_in">len</span>(train_texts)/<span class="built_in">len</span>(texts)*<span class="number">100</span>:<span class="number">.1</span>f&#125;</span>%)&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;验证集大小: <span class="subst">&#123;<span class="built_in">len</span>(val_texts)&#125;</span> (<span class="subst">&#123;<span class="built_in">len</span>(val_texts)/<span class="built_in">len</span>(texts)*<span class="number">100</span>:<span class="number">.1</span>f&#125;</span>%)&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;测试集大小: <span class="subst">&#123;<span class="built_in">len</span>(test_texts)&#125;</span> (<span class="subst">&#123;<span class="built_in">len</span>(test_texts)/<span class="built_in">len</span>(texts)*<span class="number">100</span>:<span class="number">.1</span>f&#125;</span>%)&quot;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="3-数据集类定义"><a href="#3-数据集类定义" class="headerlink" title="3. 数据集类定义"></a>3. 数据集类定义</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">IMDbDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, texts, labels, tokenizer, max_len=<span class="number">512</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.texts = texts</span><br><span class="line">        <span class="variable language_">self</span>.labels = labels</span><br><span class="line">        <span class="variable language_">self</span>.tokenizer = tokenizer</span><br><span class="line">        <span class="variable language_">self</span>.max_len = max_len</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.texts)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        text = <span class="built_in">str</span>(<span class="variable language_">self</span>.texts[idx])</span><br><span class="line">        label = <span class="variable language_">self</span>.labels[idx]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 文本预处理：移除过长的空白字符</span></span><br><span class="line">        text = <span class="string">&#x27; &#x27;</span>.join(text.split())</span><br><span class="line"></span><br><span class="line">        encoding = <span class="variable language_">self</span>.tokenizer.encode_plus(</span><br><span class="line">            text,</span><br><span class="line">            add_special_tokens=<span class="literal">True</span>,</span><br><span class="line">            max_length=<span class="variable language_">self</span>.max_len,</span><br><span class="line">            return_token_type_ids=<span class="literal">False</span>,</span><br><span class="line">            padding=<span class="string">&#x27;max_length&#x27;</span>,</span><br><span class="line">            truncation=<span class="literal">True</span>,</span><br><span class="line">            return_attention_mask=<span class="literal">True</span>,</span><br><span class="line">            return_tensors=<span class="string">&#x27;pt&#x27;</span>,</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> &#123;</span><br><span class="line">            <span class="string">&#x27;input_ids&#x27;</span>: encoding[<span class="string">&#x27;input_ids&#x27;</span>].flatten(),</span><br><span class="line">            <span class="string">&#x27;attention_mask&#x27;</span>: encoding[<span class="string">&#x27;attention_mask&#x27;</span>].flatten(),</span><br><span class="line">            <span class="string">&#x27;labels&#x27;</span>: torch.tensor(label, dtype=torch.long)</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>

<h2 id="4-模型训练工具"><a href="#4-模型训练工具" class="headerlink" title="4. 模型训练工具"></a>4. 模型训练工具</h2><h3 id="早停机制"><a href="#早停机制" class="headerlink" title="早停机制"></a>早停机制</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">EarlyStopping</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, patience=<span class="number">5</span>, delta=<span class="number">0</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.patience = patience</span><br><span class="line">        <span class="variable language_">self</span>.delta = delta</span><br><span class="line">        <span class="variable language_">self</span>.best_score = <span class="literal">None</span></span><br><span class="line">        <span class="variable language_">self</span>.early_stop = <span class="literal">False</span></span><br><span class="line">        <span class="variable language_">self</span>.counter = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, val_loss, model, model_path</span>):</span><br><span class="line">        score = -val_loss</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.best_score <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="variable language_">self</span>.best_score = score</span><br><span class="line">            <span class="variable language_">self</span>.save_checkpoint(model, model_path)</span><br><span class="line">        <span class="keyword">elif</span> score &lt; <span class="variable language_">self</span>.best_score + <span class="variable language_">self</span>.delta:</span><br><span class="line">            <span class="variable language_">self</span>.counter += <span class="number">1</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;EarlyStopping counter: <span class="subst">&#123;self.counter&#125;</span> out of <span class="subst">&#123;self.patience&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>.counter &gt;= <span class="variable language_">self</span>.patience:</span><br><span class="line">                <span class="variable language_">self</span>.early_stop = <span class="literal">True</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="variable language_">self</span>.best_score = score</span><br><span class="line">            <span class="variable language_">self</span>.save_checkpoint(model, model_path)</span><br><span class="line">            <span class="variable language_">self</span>.counter = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">save_checkpoint</span>(<span class="params">self, model, model_path</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;保存模型检查点&quot;&quot;&quot;</span></span><br><span class="line">        os.makedirs(os.path.dirname(model_path) <span class="keyword">if</span> os.path.dirname(model_path) <span class="keyword">else</span> <span class="string">&#x27;.&#x27;</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">        torch.save(model.state_dict(), model_path)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;✅ 模型已保存到: <span class="subst">&#123;model_path&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="训练函数"><a href="#训练函数" class="headerlink" title="训练函数"></a>训练函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_model</span>(<span class="params">model, train_loader, val_loader, optimizer, scheduler, epochs=<span class="number">3</span>, model_path=<span class="string">&#x27;best_model.pth&#x27;</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;训练模型&quot;&quot;&quot;</span></span><br><span class="line">    early_stopping = EarlyStopping(patience=<span class="number">3</span>, delta=<span class="number">0.001</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;\n<span class="subst">&#123;<span class="string">&#x27;=&#x27;</span>*<span class="number">60</span>&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Epoch <span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;epochs&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;<span class="string">&#x27;=&#x27;</span>*<span class="number">60</span>&#125;</span>&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 训练阶段</span></span><br><span class="line">        model.train()</span><br><span class="line">        total_loss = <span class="number">0</span></span><br><span class="line">        train_progress = tqdm(train_loader, desc=<span class="string">f&quot;Training&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> batch <span class="keyword">in</span> train_progress:</span><br><span class="line">            input_ids = batch[<span class="string">&#x27;input_ids&#x27;</span>].to(device)</span><br><span class="line">            attention_mask = batch[<span class="string">&#x27;attention_mask&#x27;</span>].to(device)</span><br><span class="line">            labels = batch[<span class="string">&#x27;labels&#x27;</span>].to(device)</span><br><span class="line"></span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)</span><br><span class="line">            loss = outputs.loss</span><br><span class="line"></span><br><span class="line">            loss.backward()</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 梯度裁剪，防止梯度爆炸</span></span><br><span class="line">            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=<span class="number">1.0</span>)</span><br><span class="line">            </span><br><span class="line">            optimizer.step()</span><br><span class="line">            scheduler.step()</span><br><span class="line"></span><br><span class="line">            total_loss += loss.item()</span><br><span class="line">            train_progress.set_postfix(&#123;<span class="string">&#x27;loss&#x27;</span>: <span class="string">f&#x27;<span class="subst">&#123;loss.item():<span class="number">.4</span>f&#125;</span>&#x27;</span>&#125;)</span><br><span class="line"></span><br><span class="line">        avg_train_loss = total_loss / <span class="built_in">len</span>(train_loader)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;\n📊 平均训练损失: <span class="subst">&#123;avg_train_loss:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 验证阶段</span></span><br><span class="line">        val_loss = validate_model(model, val_loader)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;📊 验证损失: <span class="subst">&#123;val_loss:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 早停机制</span></span><br><span class="line">        early_stopping(val_loss, model, model_path)</span><br><span class="line">        <span class="keyword">if</span> early_stopping.early_stop:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;\n🛑 Early stopping triggered&quot;</span>)</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">validate_model</span>(<span class="params">model, val_loader</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;验证模型&quot;&quot;&quot;</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    total_loss = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        val_progress = tqdm(val_loader, desc=<span class="string">&quot;Validating&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> batch <span class="keyword">in</span> val_progress:</span><br><span class="line">            input_ids = batch[<span class="string">&#x27;input_ids&#x27;</span>].to(device)</span><br><span class="line">            attention_mask = batch[<span class="string">&#x27;attention_mask&#x27;</span>].to(device)</span><br><span class="line">            labels = batch[<span class="string">&#x27;labels&#x27;</span>].to(device)</span><br><span class="line"></span><br><span class="line">            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)</span><br><span class="line">            loss = outputs.loss</span><br><span class="line">            total_loss += loss.item()</span><br><span class="line">            val_progress.set_postfix(&#123;<span class="string">&#x27;loss&#x27;</span>: <span class="string">f&#x27;<span class="subst">&#123;loss.item():<span class="number">.4</span>f&#125;</span>&#x27;</span>&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> total_loss / <span class="built_in">len</span>(val_loader)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate_model</span>(<span class="params">model, test_loader</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;评估模型&quot;&quot;&quot;</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    total_correct = <span class="number">0</span></span><br><span class="line">    total_samples = <span class="number">0</span></span><br><span class="line">    all_predictions = []</span><br><span class="line">    all_labels = []</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        test_progress = tqdm(test_loader, desc=<span class="string">&quot;Testing&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> batch <span class="keyword">in</span> test_progress:</span><br><span class="line">            input_ids = batch[<span class="string">&#x27;input_ids&#x27;</span>].to(device)</span><br><span class="line">            attention_mask = batch[<span class="string">&#x27;attention_mask&#x27;</span>].to(device)</span><br><span class="line">            labels = batch[<span class="string">&#x27;labels&#x27;</span>].to(device)</span><br><span class="line"></span><br><span class="line">            outputs = model(input_ids, attention_mask=attention_mask)</span><br><span class="line">            logits = outputs.logits</span><br><span class="line">            predictions = torch.argmax(logits, dim=<span class="number">1</span>)</span><br><span class="line">            </span><br><span class="line">            total_correct += (predictions == labels).<span class="built_in">sum</span>().item()</span><br><span class="line">            total_samples += labels.size(<span class="number">0</span>)</span><br><span class="line">            </span><br><span class="line">            all_predictions.extend(predictions.cpu().numpy())</span><br><span class="line">            all_labels.extend(labels.cpu().numpy())</span><br><span class="line">            </span><br><span class="line">            current_acc = total_correct / total_samples <span class="keyword">if</span> total_samples &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">            test_progress.set_postfix(&#123;<span class="string">&#x27;accuracy&#x27;</span>: <span class="string">f&#x27;<span class="subst">&#123;current_acc:<span class="number">.4</span>f&#125;</span>&#x27;</span>&#125;)</span><br><span class="line">    </span><br><span class="line">    accuracy = total_correct / total_samples</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\n🎯 测试准确率: <span class="subst">&#123;accuracy:<span class="number">.4</span>f&#125;</span> (<span class="subst">&#123;total_correct&#125;</span>/<span class="subst">&#123;total_samples&#125;</span>)&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> accuracy, all_predictions, all_labels</span><br></pre></td></tr></table></figure>

<h2 id="5-模型初始化"><a href="#5-模型初始化" class="headerlink" title="5. 模型初始化"></a>5. 模型初始化</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 初始化Tokenizer</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;🔄 正在加载tokenizer...&quot;</span>)</span><br><span class="line">tokenizer = BertTokenizer.from_pretrained(<span class="string">&#x27;bert-base-uncased&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;✅ Tokenizer加载完成&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试tokenizer</span></span><br><span class="line">sample_text = <span class="string">&quot;This movie is absolutely amazing!&quot;</span></span><br><span class="line">tokens = tokenizer.tokenize(sample_text)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\n示例文本: <span class="subst">&#123;sample_text&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;分词结果: <span class="subst">&#123;tokens[:<span class="number">10</span>]&#125;</span>...&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;词汇表大小: <span class="subst">&#123;tokenizer.vocab_size&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建数据集和数据加载器</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;🔄 正在创建数据加载器...&quot;</span>)</span><br><span class="line"></span><br><span class="line">train_dataset = IMDbDataset(train_texts, train_labels, tokenizer)</span><br><span class="line">val_dataset = IMDbDataset(val_texts, val_labels, tokenizer)</span><br><span class="line">test_dataset = IMDbDataset(test_texts, test_labels, tokenizer)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置批次大小（可根据GPU内存调整）</span></span><br><span class="line">batch_size = <span class="number">16</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;批次大小: <span class="subst">&#123;batch_size&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line">val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=<span class="literal">False</span>)</span><br><span class="line">test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;✅ 数据加载器创建完成&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;训练批次数: <span class="subst">&#123;<span class="built_in">len</span>(train_loader)&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;验证批次数: <span class="subst">&#123;<span class="built_in">len</span>(val_loader)&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;测试批次数: <span class="subst">&#123;<span class="built_in">len</span>(test_loader)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化模型</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;🔄 正在加载BERT模型...&quot;</span>)</span><br><span class="line">model = BertForSequenceClassification.from_pretrained(</span><br><span class="line">    <span class="string">&#x27;bert-base-uncased&#x27;</span>,</span><br><span class="line">    num_labels=<span class="number">2</span>  <span class="comment"># 二分类：积极/消极</span></span><br><span class="line">).to(device)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;✅ BERT模型加载完成&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;模型参数数量: <span class="subst">&#123;<span class="built_in">sum</span>(p.numel() <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters()):,&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;可训练参数数量: <span class="subst">&#123;<span class="built_in">sum</span>(p.numel() <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters() <span class="keyword">if</span> p.requires_grad):,&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置优化器和学习率调度器</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;🔄 配置优化器和调度器...&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 超参数设置</span></span><br><span class="line">learning_rate = <span class="number">2e-5</span></span><br><span class="line">epochs = <span class="number">3</span></span><br><span class="line">eps = <span class="number">1e-8</span></span><br><span class="line"></span><br><span class="line">optimizer = AdamW(model.parameters(), lr=learning_rate, eps=eps)</span><br><span class="line"></span><br><span class="line">total_steps = <span class="built_in">len</span>(train_loader) * epochs</span><br><span class="line">scheduler = get_linear_schedule_with_warmup(</span><br><span class="line">    optimizer,</span><br><span class="line">    num_warmup_steps=<span class="number">0</span>,</span><br><span class="line">    num_training_steps=total_steps</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;✅ 优化器配置完成&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;学习率: <span class="subst">&#123;learning_rate&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;训练轮数: <span class="subst">&#123;epochs&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;总训练步数: <span class="subst">&#123;total_steps&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="6-模型训练"><a href="#6-模型训练" class="headerlink" title="6. 模型训练"></a>6. 模型训练</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 开始训练</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;🚀 开始训练模型...&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;设备: <span class="subst">&#123;device&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;批次大小: <span class="subst">&#123;batch_size&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;训练轮数: <span class="subst">&#123;epochs&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span> + <span class="string">&quot;=&quot;</span>*<span class="number">80</span>)</span><br><span class="line"></span><br><span class="line">model_path = <span class="string">&#x27;best_model.pth&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">train_model(</span><br><span class="line">    model=model,</span><br><span class="line">    train_loader=train_loader,</span><br><span class="line">    val_loader=val_loader,</span><br><span class="line">    optimizer=optimizer,</span><br><span class="line">    scheduler=scheduler,</span><br><span class="line">    epochs=epochs,</span><br><span class="line">    model_path=model_path</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n🎉 训练完成！&quot;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="7-模型评估"><a href="#7-模型评估" class="headerlink" title="7. 模型评估"></a>7. 模型评估</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载最佳模型并评估</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;🔄 加载最佳模型...&quot;</span>)</span><br><span class="line"><span class="keyword">if</span> os.path.exists(model_path):</span><br><span class="line">    model.load_state_dict(torch.load(model_path, map_location=device))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;✅ 最佳模型加载成功&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;⚠️ 最佳模型文件不存在，使用当前模型&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span> + <span class="string">&quot;=&quot;</span>*<span class="number">60</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;📊 在测试集上评估模型...&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;=&quot;</span>*<span class="number">60</span>)</span><br><span class="line"></span><br><span class="line">accuracy, predictions, true_labels = evaluate_model(model, test_loader)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 详细的评估指标</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report, confusion_matrix</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分类报告</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n📋 分类报告:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(classification_report(true_labels, predictions, target_names=[<span class="string">&#x27;消极&#x27;</span>, <span class="string">&#x27;积极&#x27;</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 混淆矩阵</span></span><br><span class="line">cm = confusion_matrix(true_labels, predictions)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n🔍 混淆矩阵:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(cm)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化混淆矩阵</span></span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>, <span class="number">6</span>))</span><br><span class="line">sns.heatmap(cm, annot=<span class="literal">True</span>, fmt=<span class="string">&#x27;d&#x27;</span>, cmap=<span class="string">&#x27;Blues&#x27;</span>, </span><br><span class="line">            xticklabels=[<span class="string">&#x27;消极&#x27;</span>, <span class="string">&#x27;积极&#x27;</span>], yticklabels=[<span class="string">&#x27;消极&#x27;</span>, <span class="string">&#x27;积极&#x27;</span>])</span><br><span class="line">plt.title(<span class="string">&#x27;混淆矩阵&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;预测标签&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;真实标签&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算各项指标</span></span><br><span class="line">tn, fp, fn, tp = cm.ravel()</span><br><span class="line">precision = tp / (tp + fp)</span><br><span class="line">recall = tp / (tp + fn)</span><br><span class="line">f1 = <span class="number">2</span> * (precision * recall) / (precision + recall)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\n📊 详细指标:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;准确率 (Accuracy): <span class="subst">&#123;accuracy:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;精确率 (Precision): <span class="subst">&#123;precision:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;召回率 (Recall): <span class="subst">&#123;recall:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;F1分数: <span class="subst">&#123;f1:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="8-预测示例"><a href="#8-预测示例" class="headerlink" title="8. 预测示例"></a>8. 预测示例</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">predict_sentiment</span>(<span class="params">text, model, tokenizer, device</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;预测单个文本的情感&quot;&quot;&quot;</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 文本预处理</span></span><br><span class="line">    text = <span class="string">&#x27; &#x27;</span>.join(<span class="built_in">str</span>(text).split())</span><br><span class="line"></span><br><span class="line">    encoding = tokenizer.encode_plus(</span><br><span class="line">        text,</span><br><span class="line">        add_special_tokens=<span class="literal">True</span>,</span><br><span class="line">        max_length=<span class="number">512</span>,</span><br><span class="line">        padding=<span class="string">&#x27;max_length&#x27;</span>,</span><br><span class="line">        truncation=<span class="literal">True</span>,</span><br><span class="line">        return_attention_mask=<span class="literal">True</span>,</span><br><span class="line">        return_tensors=<span class="string">&#x27;pt&#x27;</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    input_ids = encoding[<span class="string">&#x27;input_ids&#x27;</span>].to(device)</span><br><span class="line">    attention_mask = encoding[<span class="string">&#x27;attention_mask&#x27;</span>].to(device)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        outputs = model(input_ids, attention_mask=attention_mask)</span><br><span class="line">        logits = outputs.logits</span><br><span class="line">        probabilities = torch.nn.functional.softmax(logits, dim=<span class="number">1</span>)</span><br><span class="line">        prediction = torch.argmax(logits, dim=<span class="number">1</span>).item()</span><br><span class="line">        confidence = probabilities[<span class="number">0</span>][prediction].item()</span><br><span class="line"></span><br><span class="line">    sentiment = <span class="string">&quot;积极&quot;</span> <span class="keyword">if</span> prediction == <span class="number">1</span> <span class="keyword">else</span> <span class="string">&quot;消极&quot;</span></span><br><span class="line">    <span class="keyword">return</span> sentiment, confidence</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例预测</span></span><br><span class="line">test_texts_examples = [</span><br><span class="line">    <span class="string">&quot;This movie is absolutely amazing! I love it!&quot;</span>,</span><br><span class="line">    <span class="string">&quot;This is the worst movie I have ever seen.&quot;</span>,</span><br><span class="line">    <span class="string">&quot;The movie was okay, nothing special.&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Fantastic acting and great storyline!&quot;</span>,</span><br><span class="line">    <span class="string">&quot;I fell asleep during the movie. So boring.&quot;</span>,</span><br><span class="line">    <span class="string">&quot;The cinematography was breathtaking and the story was compelling.&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Waste of time and money. Terrible plot.&quot;</span>,</span><br><span class="line">    <span class="string">&quot;One of the best films I&#x27;ve watched this year!&quot;</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;🎬 情感分析预测示例:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;=&quot;</span>*<span class="number">80</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, text <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_texts_examples, <span class="number">1</span>):</span><br><span class="line">    sentiment, confidence = predict_sentiment(text, model, tokenizer, device)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 根据情感选择emoji</span></span><br><span class="line">    emoji = <span class="string">&quot;😊&quot;</span> <span class="keyword">if</span> sentiment == <span class="string">&quot;积极&quot;</span> <span class="keyword">else</span> <span class="string">&quot;😞&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\n<span class="subst">&#123;i&#125;</span>. 文本: <span class="subst">&#123;text&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;   预测: <span class="subst">&#123;sentiment&#125;</span> <span class="subst">&#123;emoji&#125;</span> (置信度: <span class="subst">&#123;confidence:<span class="number">.4</span>f&#125;</span>)&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;   <span class="subst">&#123;<span class="string">&#x27;-&#x27;</span>*<span class="number">60</span>&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n✅ 预测完成！&quot;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="9-模型保存和加载"><a href="#9-模型保存和加载" class="headerlink" title="9. 模型保存和加载"></a>9. 模型保存和加载</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 保存完整模型（包括tokenizer）</span></span><br><span class="line">model_save_path = <span class="string">&#x27;./bert_sentiment_model&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;💾 保存模型到: <span class="subst">&#123;model_save_path&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建保存目录</span></span><br><span class="line">os.makedirs(model_save_path, exist_ok=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存模型和tokenizer</span></span><br><span class="line">model.save_pretrained(model_save_path)</span><br><span class="line">tokenizer.save_pretrained(model_save_path)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;✅ 模型和tokenizer保存完成&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;   模型文件: <span class="subst">&#123;model_save_path&#125;</span>/pytorch_model.bin&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;   配置文件: <span class="subst">&#123;model_save_path&#125;</span>/config.json&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;   词汇表: <span class="subst">&#123;model_save_path&#125;</span>/vocab.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试模型加载</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;🔄 测试模型加载...&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载保存的模型</span></span><br><span class="line">loaded_model = BertForSequenceClassification.from_pretrained(model_save_path).to(device)</span><br><span class="line">loaded_tokenizer = BertTokenizer.from_pretrained(model_save_path)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;✅ 模型加载成功&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试加载的模型</span></span><br><span class="line">test_text = <span class="string">&quot;This movie is fantastic!&quot;</span></span><br><span class="line">sentiment, confidence = predict_sentiment(test_text, loaded_model, loaded_tokenizer, device)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\n🧪 测试预测:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;文本: <span class="subst">&#123;test_text&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;预测: <span class="subst">&#123;sentiment&#125;</span> (置信度: <span class="subst">&#123;confidence:<span class="number">.4</span>f&#125;</span>)&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n✅ 模型加载测试通过！&quot;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="10-总结和使用说明"><a href="#10-总结和使用说明" class="headerlink" title="10. 总结和使用说明"></a>10. 总结和使用说明</h2><h3 id="训练总结"><a href="#训练总结" class="headerlink" title="训练总结"></a>训练总结</h3><p>**🎉 **<strong>BERT情感分析模型训练完成！</strong></p>
<p><strong>📊 模型性能:</strong></p>
<ul>
<li><strong>测试集准确率: ~87-92%</strong></li>
<li><strong>模型参数量: 109,483,778</strong></li>
<li><strong>支持GPU加速训练</strong></li>
</ul>
<p><strong>💾 模型文件:</strong></p>
<ul>
<li>**权重文件: **<code>best_model.pth</code></li>
<li>**完整模型: **<code>./bert_sentiment_model</code></li>
</ul>
<p><strong>🔧 使用方法:</strong></p>
<ol>
<li>**加载模型: **<code>BertForSequenceClassification.from_pretrained(&#39;./bert_sentiment_model&#39;)</code></li>
<li>**加载tokenizer: **<code>BertTokenizer.from_pretrained(&#39;./bert_sentiment_model&#39;)</code></li>
<li><strong>使用</strong> <code>predict_sentiment</code>函数进行预测</li>
</ol>
<p><strong>⚙️ 超参数:</strong></p>
<ul>
<li><strong>学习率: 2e-5</strong></li>
<li><strong>批次大小: 16</strong></li>
<li><strong>训练轮数: 3</strong></li>
<li><strong>最大序列长度: 512</strong></li>
</ul>
<h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><p><strong>🎯 模型可以用于:</strong></p>
<ul>
<li><strong>电影评论情感分析</strong></li>
<li>**产品评价情感分析  **</li>
<li><strong>社交媒体文本情感分析</strong></li>
<li><strong>客户反馈分析</strong></li>
</ul>
<h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><p><strong>💡 重要提示:</strong></p>
<ul>
<li><strong>模型在英文文本上效果最佳</strong></li>
<li><strong>可以通过更多数据和更长训练时间进一步提升性能</strong></li>
<li><strong>建议在GPU上运行以获得最佳性能</strong></li>
</ul>
<p><strong>📝 技术要求:</strong></p>
<ol>
<li><strong>硬件要求</strong>: 建议使用GPU训练，CPU训练会非常慢</li>
<li><strong>内存管理</strong>: 如果GPU内存不足，可以减小 <code>batch_size</code></li>
<li><strong>训练时间</strong>: 完整训练可能需要1-3小时（取决于硬件）</li>
<li><strong>数据集</strong>: 首次运行会自动下载约84MB的IMDb数据集</li>
<li><strong>模型大小</strong>: 保存的模型约400MB</li>
</ol>
<h3 id="扩展建议"><a href="#扩展建议" class="headerlink" title="扩展建议"></a>扩展建议</h3><p><strong>🚀 进一步改进:</strong></p>
<ol>
<li><strong>数据增强</strong>: 使用同义词替换、回译等技术</li>
<li><strong>超参数调优</strong>: 尝试不同的学习率、批次大小等</li>
<li><strong>集成学习</strong>: 结合多个模型的预测结果</li>
<li><strong>领域适应</strong>: 针对特定领域进行微调</li>
<li><strong>多分类</strong>: 扩展到细粒度情感分类（如1-5星评级）</li>
</ol>
<hr>
<h2 id="🔗-相关资源"><a href="#🔗-相关资源" class="headerlink" title="🔗 相关资源"></a>🔗 相关资源</h2><ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1810.04805">BERT论文</a></li>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/docs/transformers/">Transformers库文档</a></li>
<li><a target="_blank" rel="noopener" href="http://ai.stanford.edu/~amaas/data/sentiment/">IMDb数据集</a></li>
<li><a target="_blank" rel="noopener" href="https://pytorch.org/docs/">PyTorch官方文档</a></li>
</ul>
<hr>
<p><em>本教程提供了完整的BERT情感分析解决方案，从数据准备到模型部署的全流程。代码已经过测试，可以直接运行使用。</em></p>
</article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/AI/">AI</a></div><div class="post-share"><div class="social-share" data-image="https://i.111666.best/image/0wIZQ3j5GIDM5obXp0yA3f.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related full-width" href="/posts/4a17b156/" title="Hello World"><img class="cover" src="https://jsd.012700.xyz/gh/jerryc127/CDN@latest/cover/default_bg.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">Hello World</div></div><div class="info-2"><div class="info-item-1">这是Hexo官方文章   Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot;  More info: Writing Run server1$ hexo server  More info: Server Generate static files1$ hexo generate  More info: Generating Deploy to remote sites1$ hexo deploy  More info: Deployment </div></div></div></a></nav><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="giscus-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="https://avatars.githubusercontent.com/u/149315495?s=400&amp;u=35789284796e584dbaaac1634d60d423dde4b39e&amp;v=4" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Lishengshang</div><div class="author-info-description"></div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">2</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">2</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/lishengshang" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="https://www.bilibili.com/" target="_blank" title="B站"><i class="fa-brands fa-bilibili"></i></a><a class="social-icon" href="https://music.163.com/" target="_blank" title="网易云音乐"><i class="fa-solid fa-compact-disc"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#BERT%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90%E8%AE%AD%E7%BB%83%E6%95%99%E7%A8%8B-IMDb%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">1.</span> <span class="toc-text">BERT情感分析训练教程 - IMDb数据集</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9B%AE%E5%BD%95"><span class="toc-number">1.1.</span> <span class="toc-text">目录</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87%E5%92%8C%E4%BE%9D%E8%B5%96%E5%AE%89%E8%A3%85"><span class="toc-number">1.2.</span> <span class="toc-text">1. 环境准备和依赖安装</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8B%E8%BD%BD%E5%92%8C%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-number">1.3.</span> <span class="toc-text">2. 数据集下载和预处理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%8B%E8%BD%BDIMDb%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">1.3.1.</span> <span class="toc-text">下载IMDb数据集</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8A%A0%E8%BD%BD%E5%92%8C%E9%A2%84%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE"><span class="toc-number">1.3.2.</span> <span class="toc-text">加载和预处理数据</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E6%95%B0%E6%8D%AE%E9%9B%86%E7%B1%BB%E5%AE%9A%E4%B9%89"><span class="toc-number">1.4.</span> <span class="toc-text">3. 数据集类定义</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E5%B7%A5%E5%85%B7"><span class="toc-number">1.5.</span> <span class="toc-text">4. 模型训练工具</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%97%A9%E5%81%9C%E6%9C%BA%E5%88%B6"><span class="toc-number">1.5.1.</span> <span class="toc-text">早停机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E5%87%BD%E6%95%B0"><span class="toc-number">1.5.2.</span> <span class="toc-text">训练函数</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E6%A8%A1%E5%9E%8B%E5%88%9D%E5%A7%8B%E5%8C%96"><span class="toc-number">1.6.</span> <span class="toc-text">5. 模型初始化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83"><span class="toc-number">1.7.</span> <span class="toc-text">6. 模型训练</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0"><span class="toc-number">1.8.</span> <span class="toc-text">7. 模型评估</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-%E9%A2%84%E6%B5%8B%E7%A4%BA%E4%BE%8B"><span class="toc-number">1.9.</span> <span class="toc-text">8. 预测示例</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-%E6%A8%A1%E5%9E%8B%E4%BF%9D%E5%AD%98%E5%92%8C%E5%8A%A0%E8%BD%BD"><span class="toc-number">1.10.</span> <span class="toc-text">9. 模型保存和加载</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10-%E6%80%BB%E7%BB%93%E5%92%8C%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E"><span class="toc-number">1.11.</span> <span class="toc-text">10. 总结和使用说明</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E6%80%BB%E7%BB%93"><span class="toc-number">1.11.1.</span> <span class="toc-text">训练总结</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-number">1.11.2.</span> <span class="toc-text">应用场景</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9"><span class="toc-number">1.11.3.</span> <span class="toc-text">注意事项</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%89%A9%E5%B1%95%E5%BB%BA%E8%AE%AE"><span class="toc-number">1.11.4.</span> <span class="toc-text">扩展建议</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%94%97-%E7%9B%B8%E5%85%B3%E8%B5%84%E6%BA%90"><span class="toc-number">1.12.</span> <span class="toc-text">🔗 相关资源</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/posts/c09a4ded/" title="BERT情感分析"><img src="https://i.111666.best/image/0wIZQ3j5GIDM5obXp0yA3f.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="BERT情感分析"/></a><div class="content"><a class="title" href="/posts/c09a4ded/" title="BERT情感分析">BERT情感分析</a><time datetime="2025-06-08T05:24:36.000Z" title="发表于 2025-06-08 13:24:36">2025-06-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/4a17b156/" title="Hello World"><img src="https://jsd.012700.xyz/gh/jerryc127/CDN@latest/cover/default_bg.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Hello World"/></a><div class="content"><a class="title" href="/posts/4a17b156/" title="Hello World">Hello World</a><time datetime="2024-10-23T10:13:21.000Z" title="发表于 2024-10-23 18:13:21">2024-10-23</time></div></div></div></div></div></div></main><footer id="footer" style="background: transparent;"><div id="footer-wrap"><div class="copyright">&copy;2024 - 2025 By Lishengshang</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.3.5</a></div><div>
<i class="fas fa-heart faa-float animated" style="color:red"></i>
<span id="timeDate">载入天数...</span>
<span id="times">载入时分秒...</span>
</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="前往评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><div class="js-pjax"><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = null

  const getGiscusTheme = theme => theme === 'dark' ? 'dark' : 'light'

  const createScriptElement = config => {
    const ele = document.createElement('script')
    Object.entries(config).forEach(([key, value]) => {
      ele.setAttribute(key, value)
    })
    return ele
  }

  const loadGiscus = (el = document, key) => {
    const mappingConfig = isShuoshuo
      ? { 'data-mapping': 'specific', 'data-term': key }
      : { 'data-mapping': (option && option['data-mapping']) || 'pathname' }

    const giscusConfig = {
      src: 'https://giscus.app/client.js',
      'data-repo': 'lishengshang/lishengshang.github.io',
      'data-repo-id': 'R_kgDOOw4r5Q',
      'data-category-id': 'DIC_kwDOOw4r5c4Cqn7i',
      'data-theme': getGiscusTheme(document.documentElement.getAttribute('data-theme')),
      'data-reactions-enabled': '1',
      crossorigin: 'anonymous',
      async: true,
      ...option,
      ...mappingConfig
    }

    const scriptElement = createScriptElement(giscusConfig)

    el.querySelector('#giscus-wrap').appendChild(scriptElement)

    if (isShuoshuo) {
      window.shuoshuoComment.destroyGiscus = () => {
        if (el.children.length) {
          el.innerHTML = ''
          el.classList.add('no-comment')
        }
      }
    }
  }

  const changeGiscusTheme = theme => {
    const iframe = document.querySelector('#giscus-wrap iframe')
    if (iframe) {
      const message = {
        giscus: {
          setConfig: {
            theme: getGiscusTheme(theme)
          }
        }
      }
      iframe.contentWindow.postMessage(message, 'https://giscus.app')
    }
  }

  btf.addGlobalFn('themeChange', changeGiscusTheme, 'giscus')

  if (isShuoshuo) {
    'Giscus' === 'Giscus'
      ? window.shuoshuoComment = { loadComment: loadGiscus }
      : window.loadOtherComment = loadGiscus
    return
  }

  if ('Giscus' === 'Giscus' || !true) {
    if (true) btf.loadComment(document.getElementById('giscus-wrap'), loadGiscus)
    else loadGiscus()
  } else {
    window.loadOtherComment = loadGiscus
  }
})()</script></div><div class="aplayer no-destroy" data-id="13718038058" data-server="netease" data-type="playlist" data-fixed="true" data-autoplay="true"> </div><script defer src="/live2d-widget/dist/autoload.js"></script><script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script><script src="/js/custom/duration.js"></script><script defer src="/js/custom/bubble.js"></script><script src="/js/custom/visitor.js"></script><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="false"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="199" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-show-text" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-show-text.min.js" data-mobile="false" data-text="I,LOVE,YOU" data-fontsize="14px" data-random="true" async="async"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/metingjs/dist/Meting.min.js"></script><script>(() => {
  const destroyAplayer = () => {
    if (window.aplayers) {
      for (let i = 0; i < window.aplayers.length; i++) {
        if (!window.aplayers[i].options.fixed) {
          window.aplayers[i].destroy()
        }
      }
    }
  }

  const runMetingJS = () => {
    typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()
  }

  btf.addGlobalFn('pjaxSend', destroyAplayer, 'destroyAplayer')
  btf.addGlobalFn('pjaxComplete', loadMeting, 'runMetingJS')
})()</script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>(() => {
  const pjaxSelectors = ["meta[name=\"description\"]","link[rel=\"canonical\"]","head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

  window.pjax = new Pjax({
    elements: 'a:not([target="_blank"])',
    selectors: pjaxSelectors,
    cacheBust: false,
    analytics: false,
    scrollRestoration: false
  })

  const triggerPjaxFn = (val) => {
    if (!val) return
    Object.values(val).forEach(fn => fn())
  }

  document.addEventListener('pjax:send', () => {
    // removeEventListener
    btf.removeGlobalFnEvent('pjaxSendOnce')
    btf.removeGlobalFnEvent('themeChange')

    // reset readmode
    const $bodyClassList = document.body.classList
    if ($bodyClassList.contains('read-mode')) $bodyClassList.remove('read-mode')

    triggerPjaxFn(window.globalFn.pjaxSend)
  })

  document.addEventListener('pjax:complete', () => {
    btf.removeGlobalFnEvent('pjaxCompleteOnce')
    document.querySelectorAll('script[data-pjax]').forEach(item => {
      const newScript = document.createElement('script')
      const content = item.text || item.textContent || item.innerHTML || ""
      Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
      newScript.appendChild(document.createTextNode(content))
      item.parentNode.replaceChild(newScript, item)
    })

    triggerPjaxFn(window.globalFn.pjaxComplete)
  })

  document.addEventListener('pjax:error', e => {
    if (e.request.status === 404) {
      const usePjax = true
      false 
        ? (usePjax ? pjax.loadUrl('/404.html') : window.location.href = '/404.html')
        : window.location.href = e.request.responseURL
    }
  })
})()</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --><script data-pjax>
  function butterfly_footer_beautify_injector_config(){
    var parent_div_git = document.getElementById('footer-wrap');
    var item_html = '<div id="ghbdages" style="overflow:hidden;max-height:90px;height:auto;text-align:center;margin-top:10px"><div class="swiper-wrapper"><div class="swiper-slide"><a class="github-badge" target="_blank" href="https://hexo.io/" style="margin-inline:5px" title="博客框架为Hexo_v7.3.0"><img src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&amp;logo=hexo" alt=""/></a><a class="github-badge" target="_blank" href="https://butterfly.js.org/" style="margin-inline:5px" title="主题版本Butterfly_v5.3.5"><img src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&amp;logo=bitdefender" alt=""/></a><a class="github-badge" target="_blank" href="https://www.jsdelivr.com/" style="margin-inline:5px" title="本站使用JsDelivr为静态资源提供CDN加速"><img src="https://img.shields.io/badge/CDN-jsDelivr-orange?style=flat&amp;logo=jsDelivr" alt=""/></a></div><div class="swiper-slide"><a class="github-badge" target="_blank" href="https://github.com/" style="margin-inline:5px" title="本站项目由Github托管"><img src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&amp;logo=GitHub" alt=""/></a><a class="github-badge" target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" style="margin-inline:5px" title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"><img src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&amp;logo=Claris" alt=""/></a></div></div></div><style>a.github-badge:hover:before {display:none}</style>';
    console.log('已挂载butterfly_footer_beautify')
    parent_div_git.insertAdjacentHTML("beforeend",item_html)
    }
  var elist = 'null'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_footer_beautify_injector_config();
  }
  else if (epage === cpage){
    butterfly_footer_beautify_injector_config();
  }
  </script><script defer src="https://unpkg.zhimg.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://unpkg.zhimg.com/hexo-butterfly-footer-beautify/lib/swiperbdage_init.min.js"></script><!-- hexo injector body_end end --></body></html>